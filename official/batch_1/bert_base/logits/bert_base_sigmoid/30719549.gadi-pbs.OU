Loading python3/3.9.2
  Loading requirement: intel-mkl/2020.3.304
Loading tensorflow/2.6.0
  Loading requirement: cuda/11.4.1 cudnn/8.2.2-cuda11.4 nccl/2.10.3-cuda11.4
    openmpi/4.1.1
/home/576/dma576/lib/python3.7/site-packages/nltk/parse/malt.py:206: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if ret is not 0:
2021-11-02 01:15:25.807485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31024 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3d:00.0, compute capability: 7.0
2021-11-02 01:15:25.809481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31024 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0
All model checkpoint layers were used when initializing TFBertForSequenceClassification.

All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /scratch/oe7/rp3665/models/bert_base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.
Traceback (most recent call last):
  File "/scratch/oe7/rp3665/scripts/batch_1/bert_base/logits/bert_base_sigmoid/bert_base_sentence_classification_with_bioasq_preprocessing_finaldraft.py", line 194, in <module>
    datasets = load_dataset('csv', data_files={"train": '/scratch/oe7/rp3665/datasets/training_data.csv', 
  File "/home/576/rp3665/.local/lib/python3.9/site-packages/datasets/load.py", line 1084, in load_dataset
    builder_instance = load_dataset_builder(
  File "/home/576/rp3665/.local/lib/python3.9/site-packages/datasets/load.py", line 948, in load_dataset_builder
    data_files = _resolve_data_files_locally_or_by_urls(".", data_files)
  File "/home/576/rp3665/.local/lib/python3.9/site-packages/datasets/load.py", line 269, in _resolve_data_files_locally_or_by_urls
    return {
  File "/home/576/rp3665/.local/lib/python3.9/site-packages/datasets/load.py", line 270, in <dictcomp>
    k: _resolve_data_files_locally_or_by_urls(base_path, v, allowed_extensions=allowed_extensions)
  File "/home/576/rp3665/.local/lib/python3.9/site-packages/datasets/load.py", line 266, in _resolve_data_files_locally_or_by_urls
    raise FileNotFoundError(error_msg)
FileNotFoundError: Unable to resolve any data file that matches '/scratch/oe7/rp3665/datasets/test_data.csv' at /scratch/oe7/rp3665/scripts/batch_1/bert_base/logits

======================================================================================
                  Resource Usage on 2021-11-02 01:15:51:
   Job Id:             30719549.gadi-pbs
   Project:            oe7
   Exit Status:        1
   Service Units:      0.66
   NCPUs Requested:    24                     NCPUs Used: 24              
                                           CPU Time Used: 00:00:09                                   
   Memory Requested:   16.0GB                Memory Used: 2.5GB           
   Walltime requested: 10:00:00            Walltime Used: 00:00:33        
   JobFS requested:    100.0GB                JobFS used: 0B              
======================================================================================
